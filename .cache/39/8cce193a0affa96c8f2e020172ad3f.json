{"id":"node_modules/apache-arrow/ipc/writer.js","dependencies":[{"name":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js.map","includedInParent":true,"mtime":1620712940685},{"name":"/Users/yangjunran/Desktop/github/sv-demo/package.json","includedInParent":true,"mtime":1620836303330},{"name":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/package.json","includedInParent":true,"mtime":1620712940685},{"name":"../table","loc":{"line":20,"column":24},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/table.js"},{"name":"./message","loc":{"line":21,"column":26},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/message.js"},{"name":"../column","loc":{"line":22,"column":25},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/column.js"},{"name":"../type","loc":{"line":23,"column":23},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/type.js"},{"name":"../schema","loc":{"line":24,"column":25},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/schema.js"},{"name":"./metadata/message","loc":{"line":26,"column":25},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/metadata/message.js"},{"name":"./metadata/file","loc":{"line":27,"column":23},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/metadata/file.js"},{"name":"../enum","loc":{"line":28,"column":23},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/enum.js"},{"name":"../visitor/typecomparator","loc":{"line":29,"column":33},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/visitor/typecomparator.js"},{"name":"../io/stream","loc":{"line":30,"column":25},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/io/stream.js"},{"name":"../visitor/vectorassembler","loc":{"line":31,"column":34},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/visitor/vectorassembler.js"},{"name":"../visitor/jsontypeassembler","loc":{"line":32,"column":36},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/visitor/jsontypeassembler.js"},{"name":"../visitor/jsonvectorassembler","loc":{"line":33,"column":38},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/visitor/jsonvectorassembler.js"},{"name":"../util/buffer","loc":{"line":34,"column":25},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/util/buffer.js"},{"name":"../recordbatch","loc":{"line":35,"column":30},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/recordbatch.js"},{"name":"../io/interfaces","loc":{"line":36,"column":29},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/io/interfaces.js"},{"name":"../util/compat","loc":{"line":37,"column":25},"parent":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/ipc/writer.js","resolved":"/Users/yangjunran/Desktop/github/sv-demo/node_modules/apache-arrow/util/compat.js"}],"generated":{"js":"\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.RecordBatchJSONWriter = exports.RecordBatchFileWriter = exports.RecordBatchStreamWriter = exports.RecordBatchWriter = void 0;\nconst table_1 = require(\"../table\");\nconst message_1 = require(\"./message\");\nconst column_1 = require(\"../column\");\nconst type_1 = require(\"../type\");\nconst schema_1 = require(\"../schema\");\nconst message_2 = require(\"./metadata/message\");\nconst metadata = require(\"./metadata/message\");\nconst file_1 = require(\"./metadata/file\");\nconst enum_1 = require(\"../enum\");\nconst typecomparator_1 = require(\"../visitor/typecomparator\");\nconst stream_1 = require(\"../io/stream\");\nconst vectorassembler_1 = require(\"../visitor/vectorassembler\");\nconst jsontypeassembler_1 = require(\"../visitor/jsontypeassembler\");\nconst jsonvectorassembler_1 = require(\"../visitor/jsonvectorassembler\");\nconst buffer_1 = require(\"../util/buffer\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst interfaces_1 = require(\"../io/interfaces\");\nconst compat_1 = require(\"../util/compat\");\nclass RecordBatchWriter extends interfaces_1.ReadableInterop {\n    constructor(options) {\n        super();\n        this._position = 0;\n        this._started = false;\n        // @ts-ignore\n        this._sink = new stream_1.AsyncByteQueue();\n        this._schema = null;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n        compat_1.isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n    /** @nocollapse */\n    // @ts-ignore\n    static throughNode(options) {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    static throughDOM(\n    // @ts-ignore\n    writableStrategy, \n    // @ts-ignore\n    readableStrategy) {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n    toString(sync = false) {\n        return this._sink.toString(sync);\n    }\n    toUint8Array(sync = false) {\n        return this._sink.toUint8Array(sync);\n    }\n    writeAll(input) {\n        if (compat_1.isPromise(input)) {\n            return input.then((x) => this.writeAll(x));\n        }\n        else if (compat_1.isAsyncIterable(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, input);\n    }\n    get closed() { return this._sink.closed; }\n    [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    toDOMStream(options) { return this._sink.toDOMStream(options); }\n    toNodeStream(options) { return this._sink.toNodeStream(options); }\n    close() {\n        return this.reset()._sink.close();\n    }\n    abort(reason) {\n        return this.reset()._sink.abort(reason);\n    }\n    finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    reset(sink = this._sink, schema = null) {\n        if ((sink === this._sink) || (sink instanceof stream_1.AsyncByteQueue)) {\n            this._sink = sink;\n        }\n        else {\n            this._sink = new stream_1.AsyncByteQueue();\n            if (sink && compat_1.isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            }\n            else if (sink && compat_1.isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n        if (!schema || !(typecomparator_1.compareSchemas(schema, this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            }\n            else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n        return this;\n    }\n    write(payload) {\n        let schema = null;\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        }\n        else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        }\n        else if (payload instanceof table_1.Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n        else if (payload instanceof recordbatch_1.RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n        if (schema && !typecomparator_1.compareSchemas(schema, this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n        if (payload instanceof recordbatch_1.RecordBatch) {\n            if (!(payload instanceof recordbatch_1._InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        }\n        else if (payload instanceof table_1.Table) {\n            this.writeAll(payload.chunks);\n        }\n        else if (compat_1.isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n    _writeMessage(message, alignment = 8) {\n        const a = alignment - 1;\n        const buffer = message_2.Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n        if (message.headerType === enum_1.MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new file_1.FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n        else if (message.headerType === enum_1.MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new file_1.FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) {\n            this._write(buffer);\n        }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n    _write(chunk) {\n        if (this._started) {\n            const buffer = buffer_1.toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n    _writeSchema(schema) {\n        return this._writeMessage(message_2.Message.from(schema));\n    }\n    // @ts-ignore\n    _writeFooter(schema) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n    _writeMagic() {\n        return this._write(message_1.MAGIC);\n    }\n    _writePadding(nBytes) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n    _writeRecordBatch(batch) {\n        const { byteLength, nodes, bufferRegions, buffers } = vectorassembler_1.VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = message_2.Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n    _writeDictionaryBatch(dictionary, id, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = vectorassembler_1.VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = message_2.Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n    _writeBodyBuffers(buffers) {\n        let buffer;\n        let size, padding;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n    _writeDictionaries(batch) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? dictionary.chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\nexports.RecordBatchWriter = RecordBatchWriter;\n/** @ignore */\nclass RecordBatchStreamWriter extends RecordBatchWriter {\n    /** @nocollapse */\n    static writeAll(input, options) {\n        const writer = new RecordBatchStreamWriter(options);\n        if (compat_1.isPromise(input)) {\n            return input.then((x) => writer.writeAll(x));\n        }\n        else if (compat_1.isAsyncIterable(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\nexports.RecordBatchStreamWriter = RecordBatchStreamWriter;\n/** @ignore */\nclass RecordBatchFileWriter extends RecordBatchWriter {\n    /** @nocollapse */\n    static writeAll(input) {\n        const writer = new RecordBatchFileWriter();\n        if (compat_1.isPromise(input)) {\n            return input.then((x) => writer.writeAll(x));\n        }\n        else if (compat_1.isAsyncIterable(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n    // @ts-ignore\n    _writeSchema(schema) {\n        return this._writeMagic()._writePadding(2);\n    }\n    _writeFooter(schema) {\n        const buffer = file_1.Footer.encode(new file_1.Footer(schema, enum_1.MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\nexports.RecordBatchFileWriter = RecordBatchFileWriter;\n/** @ignore */\nclass RecordBatchJSONWriter extends RecordBatchWriter {\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n    /** @nocollapse */\n    static writeAll(input) {\n        return new RecordBatchJSONWriter().writeAll(input);\n    }\n    _writeMessage() { return this; }\n    // @ts-ignore\n    _writeFooter(schema) { return this; }\n    _writeSchema(schema) {\n        return this._write(`{\\n  \"schema\": ${JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)}`);\n    }\n    _writeDictionaries(batch) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    _writeDictionaryBatch(dictionary, id, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new file_1.FileBlock(0, 0, 0));\n        return this;\n    }\n    _writeRecordBatch(batch) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    close() {\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new file_1.FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n        this._dictionaries = [];\n        this._recordBatches = [];\n        return super.close();\n    }\n}\nexports.RecordBatchJSONWriter = RecordBatchJSONWriter;\n/** @ignore */\nfunction writeAll(writer, input) {\n    let chunks = input;\n    if (input instanceof table_1.Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n/** @ignore */\nasync function writeAllAsync(writer, batches) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }) {\n    const assembler = new jsontypeassembler_1.JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !type_1.DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary, id, isDelta = false) {\n    const field = new schema_1.Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = jsonvectorassembler_1.JSONVectorAssembler.assemble(new column_1.Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n/** @ignore */\nfunction recordBatchToJSON(records) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': jsonvectorassembler_1.JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n\n\n"},"sourceMaps":{"js":{"version":3,"sources":["ipc/writer.ts"],"names":[],"mappings":";AAAA,6DAA6D;AAC7D,+DAA+D;AAC/D,wDAAwD;AACxD,6DAA6D;AAC7D,oDAAoD;AACpD,6DAA6D;AAC7D,6DAA6D;AAC7D,EAAE;AACF,+CAA+C;AAC/C,EAAE;AACF,6DAA6D;AAC7D,8DAA8D;AAC9D,yDAAyD;AACzD,4DAA4D;AAC5D,0DAA0D;AAC1D,qBAAqB;;;AAErB,oCAAiC;AACjC,uCAAkC;AAElC,sCAAmC;AACnC,kCAAmC;AACnC,sCAA0C;AAC1C,gDAA6C;AAC7C,+CAA+C;AAC/C,0CAAoD;AACpD,kCAAyD;AACzD,8DAA2D;AAC3D,yCAA4D;AAC5D,gEAA6D;AAC7D,oEAAiE;AACjE,wEAAqE;AACrE,2CAAoE;AACpE,gDAAmF;AACnF,iDAAuF;AACvF,2CAA6H;AAgB7H,MAAa,iBAA+D,SAAQ,4BAA2B;IAiB3G,YAAY,OAAwC;QAChD,KAAK,EAAE,CAAC;QAMF,cAAS,GAAG,CAAC,CAAC;QACd,aAAQ,GAAG,KAAK,CAAC;QAG3B,aAAa;QACH,UAAK,GAAG,IAAI,uBAAc,EAAE,CAAC;QAC7B,YAAO,GAAkB,IAAI,CAAC;QAC9B,sBAAiB,GAAgB,EAAE,CAAC;QACpC,uBAAkB,GAAgB,EAAE,CAAC;QACrC,4BAAuB,GAAG,IAAI,GAAG,EAAkB,CAAC;QAd1D,iBAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,GAAG,EAAE,WAAW,EAAE,IAAI,EAAE,oBAAoB,EAAE,KAAK,EAAE,CAAC,CAAC;QACpF,IAAI,CAAC,YAAY,GAAG,CAAC,OAAO,OAAO,CAAC,WAAW,KAAK,SAAS,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,CAAC;QAC5F,IAAI,CAAC,qBAAqB,GAAG,CAAC,OAAO,OAAO,CAAC,oBAAoB,KAAK,SAAS,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,oBAAoB,CAAC,CAAC,CAAC,KAAK,CAAC;IAC5H,CAAC;IApBD,kBAAkB;IAClB,aAAa;IACN,MAAM,CAAC,WAAW,CAAC,OAAmE;QACzF,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;IACvE,CAAC;IACD,kBAAkB;IACX,MAAM,CAAC,UAAU;IACpB,aAAa;IACb,gBAA6E;IAC7E,aAAa;IACb,gBAAyD;QAEzD,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;IACtE,CAAC;IAsBM,QAAQ,CAAC,OAAY,KAAK;QAC7B,OAAO,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC,IAAI,CAA6B,CAAC;IACjE,CAAC;IAGM,YAAY,CAAC,OAAY,KAAK;QACjC,OAAO,IAAI,CAAC,KAAK,CAAC,YAAY,CAAC,IAAI,CAAqC,CAAC;IAC7E,CAAC;IAMM,QAAQ,CAAC,KAA6F;QACzG,IAAI,kBAAS,CAAM,KAAK,CAAC,EAAE;YACvB,OAAO,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;SAC9C;aAAM,IAAI,wBAAe,CAAiB,KAAK,CAAC,EAAE;YAC/C,OAAO,aAAa,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;SACrC;QACD,OAAO,QAAQ,CAAC,IAAI,EAAQ,KAAK,CAAC,CAAC;IACvC,CAAC;IAED,IAAW,MAAM,KAAK,OAAO,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC;IAC1C,CAAC,MAAM,CAAC,aAAa,CAAC,KAAK,OAAO,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,aAAa,CAAC,EAAE,CAAC,CAAC,CAAC;IACvE,WAAW,CAAC,OAAkC,IAAI,OAAO,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAC3F,YAAY,CAAC,OAA0C,IAAI,OAAO,IAAI,CAAC,KAAK,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAErG,KAAK;QACR,OAAO,IAAI,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;IACtC,CAAC;IACM,KAAK,CAAC,MAAY;QACrB,OAAO,IAAI,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;IAC5C,CAAC;IACM,MAAM;QACT,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;QACxE,OAAO,IAAI,CAAC;IAChB,CAAC;IACM,KAAK,CAAC,OAA2C,IAAI,CAAC,KAAK,EAAE,SAA2B,IAAI;QAC/F,IAAI,CAAC,IAAI,KAAK,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,YAAY,uBAAc,CAAC,EAAE;YAC3D,IAAI,CAAC,KAAK,GAAG,IAAsB,CAAC;SACvC;aAAM;YACH,IAAI,CAAC,KAAK,GAAG,IAAI,uBAAc,EAAE,CAAC;YAClC,IAAI,IAAI,IAAI,4BAAmB,CAAC,IAAI,CAAC,EAAE;gBACnC,IAAI,CAAC,WAAW,CAAC,EAAE,IAAI,EAAE,OAAO,EAAE,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;aACpD;iBAAM,IAAI,IAAI,IAAI,6BAAoB,CAAC,IAAI,CAAC,EAAE;gBAC3C,IAAI,CAAC,YAAY,CAAC,EAAE,UAAU,EAAE,KAAK,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;aACvD;SACJ;QAED,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,OAAO,EAAE;YAC/B,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;SACnC;QAED,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC;QACtB,IAAI,CAAC,iBAAiB,GAAG,EAAE,CAAC;QAC5B,IAAI,CAAC,kBAAkB,GAAG,EAAE,CAAC;QAC7B,IAAI,CAAC,uBAAuB,GAAG,IAAI,GAAG,EAAE,CAAC;QAEzC,IAAI,CAAC,MAAM,IAAI,CAAC,CAAC,+BAAc,CAAC,MAAM,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE;YACpD,IAAI,MAAM,KAAK,IAAI,EAAE;gBACjB,IAAI,CAAC,SAAS,GAAG,CAAC,CAAC;gBACnB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;aACvB;iBAAM;gBACH,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;gBACrB,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;gBACtB,IAAI,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC;aAC7B;SACJ;QAED,OAAO,IAAI,CAAC;IAChB,CAAC;IAEM,KAAK,CAAC,OAAqE;QAC9E,IAAI,MAAM,GAAqB,IAAI,CAAC;QAEpC,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE;YACb,MAAM,IAAI,KAAK,CAAC,6BAA6B,CAAC,CAAC;SAClD;aAAM,IAAI,OAAO,KAAK,IAAI,IAAI,OAAO,KAAK,SAAS,EAAE;YAClD,OAAO,IAAI,CAAC,MAAM,EAAE,IAAI,SAAS,CAAC;SACrC;aAAM,IAAI,OAAO,YAAY,aAAK,IAAI,CAAC,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAC,EAAE;YAC/D,OAAO,IAAI,CAAC,MAAM,EAAE,IAAI,SAAS,CAAC;SACrC;aAAM,IAAI,OAAO,YAAY,yBAAW,IAAI,CAAC,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAC,EAAE;YACrE,OAAO,IAAI,CAAC,MAAM,EAAE,IAAI,SAAS,CAAC;SACrC;QAED,IAAI,MAAM,IAAI,CAAC,+BAAc,CAAC,MAAM,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE;YACjD,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,YAAY,EAAE;gBACpC,OAAO,IAAI,CAAC,KAAK,EAAE,CAAC;aACvB;YACD,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;SAClC;QAED,IAAI,OAAO,YAAY,yBAAW,EAAE;YAChC,IAAI,CAAC,CAAC,OAAO,YAAY,kDAAoC,CAAC,EAAE;gBAC5D,IAAI,CAAC,iBAAiB,CAAC,OAAO,CAAC,CAAC;aACnC;SACJ;aAAM,IAAI,OAAO,YAAY,aAAK,EAAE;YACjC,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;SACjC;aAAM,IAAI,mBAAU,CAAC,OAAO,CAAC,EAAE;YAC5B,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;SAC1B;IACL,CAAC;IAES,aAAa,CAA0B,OAAmB,EAAE,SAAS,GAAG,CAAC;QAC/E,MAAM,CAAC,GAAG,SAAS,GAAG,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,iBAAO,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;QACvC,MAAM,cAAc,GAAG,MAAM,CAAC,UAAU,CAAC;QACzC,MAAM,UAAU,GAAG,CAAC,IAAI,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,WAAW,GAAG,CAAC,cAAc,GAAG,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAC3D,MAAM,aAAa,GAAG,WAAW,GAAG,cAAc,GAAG,UAAU,CAAC;QAEhE,IAAI,OAAO,CAAC,UAAU,KAAK,oBAAa,CAAC,WAAW,EAAE;YAClD,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,IAAI,gBAAS,CAAC,WAAW,EAAE,OAAO,CAAC,UAAU,EAAE,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;SAChG;aAAM,IAAI,OAAO,CAAC,UAAU,KAAK,oBAAa,CAAC,eAAe,EAAE;YAC7D,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,IAAI,gBAAS,CAAC,WAAW,EAAE,OAAO,CAAC,UAAU,EAAE,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;SAC/F;QAED,4EAA4E;QAC5E,IAAI,CAAC,IAAI,CAAC,qBAAqB,EAAE;YAC7B,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;SAClC;QACD,qDAAqD;QACrD,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,WAAW,GAAG,UAAU,CAAC,CAAC,CAAC;QACrD,uBAAuB;QACvB,IAAI,cAAc,GAAG,CAAC,EAAE;YAAE,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;SAAE;QAChD,oBAAoB;QACpB,OAAO,IAAI,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC;IAC7C,CAAC;IAES,MAAM,CAAC,KAA2B;QACxC,IAAI,IAAI,CAAC,QAAQ,EAAE;YACf,MAAM,MAAM,GAAG,qBAAY,CAAC,KAAK,CAAC,CAAC;YACnC,IAAI,MAAM,IAAI,MAAM,CAAC,UAAU,GAAG,CAAC,EAAE;gBACjC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;gBACzB,IAAI,CAAC,SAAS,IAAI,MAAM,CAAC,UAAU,CAAC;aACvC;SACJ;QACD,OAAO,IAAI,CAAC;IAChB,CAAC;IAES,YAAY,CAAC,MAAiB;QACpC,OAAO,IAAI,CAAC,aAAa,CAAC,iBAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC;IACpD,CAAC;IAED,aAAa;IACH,YAAY,CAAC,MAAiB;QACpC,YAAY;QACZ,OAAO,IAAI,CAAC,qBAAqB;YAC7B,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAC/B,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC;IAES,WAAW;QACjB,OAAO,IAAI,CAAC,MAAM,CAAC,eAAK,CAAC,CAAC;IAC9B,CAAC;IAES,aAAa,CAAC,MAAc;QAClC,OAAO,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,UAAU,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;IACnE,CAAC;IAES,iBAAiB,CAAC,KAAqB;QAC7C,MAAM,EAAE,UAAU,EAAE,KAAK,EAAE,aAAa,EAAE,OAAO,EAAE,GAAG,iCAAe,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;QACtF,MAAM,WAAW,GAAG,IAAI,QAAQ,CAAC,WAAW,CAAC,KAAK,CAAC,MAAM,EAAE,KAAK,EAAE,aAAa,CAAC,CAAC;QACjF,MAAM,OAAO,GAAG,iBAAO,CAAC,IAAI,CAAC,WAAW,EAAE,UAAU,CAAC,CAAC;QACtD,OAAO,IAAI;aACN,kBAAkB,CAAC,KAAK,CAAC;aACzB,aAAa,CAAC,OAAO,CAAC;aACtB,iBAAiB,CAAC,OAAO,CAAC,CAAC;IACpC,CAAC;IAES,qBAAqB,CAAC,UAAkB,EAAE,EAAU,EAAE,OAAO,GAAG,KAAK;QAC3E,IAAI,CAAC,uBAAuB,CAAC,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,CAAC,IAAI,CAAC,uBAAuB,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACtG,MAAM,EAAE,UAAU,EAAE,KAAK,EAAE,aAAa,EAAE,OAAO,EAAE,GAAG,iCAAe,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;QAC3F,MAAM,WAAW,GAAG,IAAI,QAAQ,CAAC,WAAW,CAAC,UAAU,CAAC,MAAM,EAAE,KAAK,EAAE,aAAa,CAAC,CAAC;QACtF,MAAM,eAAe,GAAG,IAAI,QAAQ,CAAC,eAAe,CAAC,WAAW,EAAE,EAAE,EAAE,OAAO,CAAC,CAAC;QAC/E,MAAM,OAAO,GAAG,iBAAO,CAAC,IAAI,CAAC,eAAe,EAAE,UAAU,CAAC,CAAC;QAC1D,OAAO,IAAI;aACN,aAAa,CAAC,OAAO,CAAC;aACtB,iBAAiB,CAAC,OAAO,CAAC,CAAC;IACpC,CAAC;IAES,iBAAiB,CAAC,OAA0B;QAClD,IAAI,MAAuB,CAAC;QAC5B,IAAI,IAAY,EAAE,OAAe,CAAC;QAClC,KAAK,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,GAAG,CAAC,GAAG;YAC3C,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,GAAG,MAAM,CAAC,UAAU,CAAC,GAAG,CAAC,EAAE;gBACzD,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;gBACpB,IAAI,CAAC,OAAO,GAAG,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,EAAE;oBAC1C,IAAI,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;iBAC/B;aACJ;SACJ;QACD,OAAO,IAAI,CAAC;IAChB,CAAC;IAES,kBAAkB,CAAC,KAAqB;QAC9C,KAAK,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,IAAI,KAAK,CAAC,YAAY,EAAE;YAC7C,IAAI,MAAM,GAAG,IAAI,CAAC,uBAAuB,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC;YACvD,IAAI,MAAM,KAAK,CAAC,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,GAAG,CAAC,EAAE;gBACpE,MAAM,MAAM,GAAG,QAAQ,IAAI,UAAU,CAAC,CAAC,CAAE,UAAkB,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC;gBAClF,KAAK,MAAM,KAAK,IAAI,MAAM,EAAE;oBACxB,IAAI,CAAC,qBAAqB,CAAC,KAAK,EAAE,EAAE,EAAE,MAAM,GAAG,CAAC,CAAC,CAAC;oBAClD,MAAM,IAAI,KAAK,CAAC,MAAM,CAAC;iBAC1B;aACJ;SACJ;QACD,OAAO,IAAI,CAAC;IAChB,CAAC;CACJ;AArPD,8CAqPC;AAED,cAAc;AACd,MAAa,uBAAqE,SAAQ,iBAAoB;IAK1G,kBAAkB;IACX,MAAM,CAAC,QAAQ,CAA8C,KAAU,EAAE,OAAwC;QACpH,MAAM,MAAM,GAAG,IAAI,uBAAuB,CAAI,OAAO,CAAC,CAAC;QACvD,IAAI,kBAAS,CAAM,KAAK,CAAC,EAAE;YACvB,OAAO,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;SAChD;aAAM,IAAI,wBAAe,CAAiB,KAAK,CAAC,EAAE;YAC/C,OAAO,aAAa,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;SACvC;QACD,OAAO,QAAQ,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;IACnC,CAAC;CACJ;AAfD,0DAeC;AAED,cAAc;AACd,MAAa,qBAAmE,SAAQ,iBAAoB;IAKxG,kBAAkB;IACX,MAAM,CAAC,QAAQ,CAA8C,KAAU;QAC1E,MAAM,MAAM,GAAG,IAAI,qBAAqB,EAAK,CAAC;QAC9C,IAAI,kBAAS,CAAM,KAAK,CAAC,EAAE;YACvB,OAAO,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;SAChD;aAAM,IAAI,wBAAe,CAAiB,KAAK,CAAC,EAAE;YAC/C,OAAO,aAAa,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;SACvC;QACD,OAAO,QAAQ,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;IACnC,CAAC;IAED;QACI,KAAK,EAAE,CAAC;QACR,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC;IAC7B,CAAC;IAED,aAAa;IACH,YAAY,CAAC,MAAiB;QACpC,OAAO,IAAI,CAAC,WAAW,EAAE,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC;IAC/C,CAAC;IAES,YAAY,CAAC,MAAiB;QACpC,MAAM,MAAM,GAAG,aAAM,CAAC,MAAM,CAAC,IAAI,aAAM,CACnC,MAAM,EAAE,sBAAe,CAAC,EAAE,EAC1B,IAAI,CAAC,kBAAkB,EAAE,IAAI,CAAC,iBAAiB,CAClD,CAAC,CAAC;QACH,OAAO,KAAK;aACP,YAAY,CAAC,MAAM,CAAC,CAAC,mCAAmC;aACxD,MAAM,CAAC,MAAM,CAAC,CAAC,uBAAuB;aACtC,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,8BAA8B;aACvE,WAAW,EAAE,CAAC,CAAC,wBAAwB;IAChD,CAAC;CACJ;AArCD,sDAqCC;AAED,cAAc;AACd,MAAa,qBAAmE,SAAQ,iBAAoB;IAexG;QACI,KAAK,EAAE,CAAC;QACR,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC;QACzB,IAAI,CAAC,cAAc,GAAG,EAAE,CAAC;QACzB,IAAI,CAAC,aAAa,GAAG,EAAE,CAAC;IAC5B,CAAC;IAbD,kBAAkB;IACX,MAAM,CAAC,QAAQ,CAA8E,KAAU;QAC1G,OAAO,IAAI,qBAAqB,EAAK,CAAC,QAAQ,CAAC,KAAY,CAAC,CAAC;IACjE,CAAC;IAYS,aAAa,KAAK,OAAO,IAAI,CAAC,CAAC,CAAC;IAC1C,aAAa;IACH,YAAY,CAAC,MAAiB,IAAI,OAAO,IAAI,CAAC,CAAC,CAAC;IAChD,YAAY,CAAC,MAAiB;QACpC,OAAO,IAAI,CAAC,MAAM,CAAC,kBACf,IAAI,CAAC,SAAS,CAAC,EAAE,MAAM,EAAE,MAAM,CAAC,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE,EAAE,IAAI,EAAE,CAAC,CACtE,EAAE,CAAC,CAAC;IACR,CAAC;IACS,kBAAkB,CAAC,KAAqB;QAC9C,IAAI,KAAK,CAAC,YAAY,CAAC,IAAI,GAAG,CAAC,EAAE;YAC7B,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SAClC;QACD,OAAO,IAAI,CAAC;IAChB,CAAC;IACS,qBAAqB,CAAC,UAAkB,EAAE,EAAU,EAAE,OAAO,GAAG,KAAK;QAC3E,IAAI,CAAC,uBAAuB,CAAC,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,CAAC,IAAI,CAAC,uBAAuB,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACtG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,iBAAiB,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC;QACtE,IAAI,CAAC,MAAM,CAAC,GAAG,qBAAqB,CAAC,UAAU,EAAE,EAAE,EAAE,OAAO,CAAC,EAAE,CAAC,CAAC;QACjE,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,IAAI,gBAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,OAAO,IAAI,CAAC;IAChB,CAAC;IACS,iBAAiB,CAAC,KAAqB;QAC7C,IAAI,CAAC,kBAAkB,CAAC,KAAK,CAAC,CAAC;QAC/B,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAChC,OAAO,IAAI,CAAC;IAChB,CAAC;IACM,KAAK;QAER,IAAI,IAAI,CAAC,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE;YAC/B,IAAI,CAAC,MAAM,CAAC,0BAA0B,CAAC,CAAC;YACxC,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,aAAa,EAAE;gBACpC,KAAK,CAAC,kBAAkB,CAAC,KAAK,CAAC,CAAC;aACnC;YACD,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;SACxB;QAED,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,GAAG,CAAC,EAAE;YAChC,KAAK,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,EAAE,CAAC,GAAG,CAAC,GAAG;gBACvD,IAAI,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,yBAAyB,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC;gBAC7D,IAAI,CAAC,MAAM,CAAC,GAAG,iBAAiB,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;gBAC5D,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,IAAI,gBAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aACxD;YACD,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;SACxB;QAED,IAAI,IAAI,CAAC,OAAO,EAAE;YACd,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;SACtB;QAED,IAAI,CAAC,aAAa,GAAG,EAAE,CAAC;QACxB,IAAI,CAAC,cAAc,GAAG,EAAE,CAAC;QAEzB,OAAO,KAAK,CAAC,KAAK,EAAE,CAAC;IACzB,CAAC;CACJ;AA5ED,sDA4EC;AAED,cAAc;AACd,SAAS,QAAQ,CAA8C,MAA4B,EAAE,KAA0C;IACnI,IAAI,MAAM,GAAG,KAAiC,CAAC;IAC/C,IAAI,KAAK,YAAY,aAAK,EAAE;QACxB,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;QACtB,MAAM,CAAC,KAAK,CAAC,SAAS,EAAE,KAAK,CAAC,MAAM,CAAC,CAAC;KACzC;IACD,KAAK,MAAM,KAAK,IAAI,MAAM,EAAE;QACxB,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;KACvB;IACD,OAAO,MAAM,CAAC,MAAM,EAAE,CAAC;AAC3B,CAAC;AAED,cAAc;AACd,KAAK,UAAU,aAAa,CAA8C,MAA4B,EAAE,OAAsC;IAC1I,IAAI,KAAK,EAAE,MAAM,KAAK,IAAI,OAAO,EAAE;QAC/B,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;KACvB;IACD,OAAO,MAAM,CAAC,MAAM,EAAE,CAAC;AAC3B,CAAC;AAED,cAAc;AACd,SAAS,WAAW,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,QAAQ,EAAS;IAChD,MAAM,SAAS,GAAG,IAAI,qCAAiB,EAAE,CAAC;IAC1C,OAAO;QACH,MAAM,EAAE,IAAI,EAAE,UAAU,EAAE,QAAQ;QAClC,MAAM,EAAE,SAAS,CAAC,KAAK,CAAC,IAAI,CAAC;QAC7B,UAAU,EAAE,CAAC,IAAI,CAAC,QAAQ,IAAI,EAAE,CAAC,CAAC,GAAG,CAAC,WAAW,CAAC;QAClD,YAAY,EAAE,CAAC,eAAQ,CAAC,YAAY,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC;YACrD,IAAI,EAAE,IAAI,CAAC,EAAE;YACb,WAAW,EAAE,IAAI,CAAC,SAAS;YAC3B,WAAW,EAAE,SAAS,CAAC,KAAK,CAAC,IAAI,CAAC,OAAO,CAAC;SAC7C;KACJ,CAAC;AACN,CAAC;AAED,cAAc;AACd,SAAS,qBAAqB,CAAC,UAAkB,EAAE,EAAU,EAAE,OAAO,GAAG,KAAK;IAC1E,MAAM,KAAK,GAAG,IAAI,cAAK,CAAC,GAAG,EAAE,EAAE,EAAE,UAAU,CAAC,IAAI,EAAE,UAAU,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;IAC5E,MAAM,OAAO,GAAG,yCAAmB,CAAC,QAAQ,CAAC,IAAI,eAAM,CAAC,KAAK,EAAE,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;IAC9E,OAAO,IAAI,CAAC,SAAS,CAAC;QAClB,IAAI,EAAE,EAAE;QACR,SAAS,EAAE,OAAO;QAClB,MAAM,EAAE;YACJ,OAAO,EAAE,UAAU,CAAC,MAAM;YAC1B,SAAS,EAAE,OAAO;SACrB;KACJ,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;AAChB,CAAC;AAED,cAAc;AACd,SAAS,iBAAiB,CAAC,OAAoB;IAC3C,OAAO,IAAI,CAAC,SAAS,CAAC;QAClB,OAAO,EAAE,OAAO,CAAC,MAAM;QACvB,SAAS,EAAE,yCAAmB,CAAC,QAAQ,CAAC,OAAO,CAAC;KACnD,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;AAChB,CAAC","file":"writer.js","sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Vector } from '../vector';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Schema, Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { compareSchemas } from '../visitor/typecomparator';\nimport { WritableSink, AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { ArrayBufferViewInput, toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { Writable, ReadableInterop, ReadableDOMStreamOptions } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\n\nexport interface RecordBatchStreamWriterOptions {\n    /**\n     *\n     */\n    autoDestroy?: boolean;\n    /**\n     * A flag indicating whether the RecordBatchWriter should construct pre-0.15.0\n     * encapsulated IPC Messages, which reserves  4 bytes for the Message metadata\n     * length instead of 8.\n     * @see https://issues.apache.org/jira/browse/ARROW-6313\n     */\n    writeLegacyIpcFormat?: boolean;\n}\n\nexport class RecordBatchWriter<T extends { [key: string]: DataType } = any> extends ReadableInterop<Uint8Array> implements Writable<RecordBatch<T>> {\n\n    /** @nocollapse */\n    // @ts-ignore\n    public static throughNode(options?: import('stream').DuplexOptions & { autoDestroy: boolean }): import('stream').Duplex {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    public static throughDOM<T extends { [key: string]: DataType }>(\n        // @ts-ignore\n        writableStrategy?: QueuingStrategy<RecordBatch<T>> & { autoDestroy: boolean },\n        // @ts-ignore\n        readableStrategy?: { highWaterMark?: number; size?: any }\n    ): { writable: WritableStream<Table<T> | RecordBatch<T>>; readable: ReadableStream<Uint8Array> } {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n\n    constructor(options?: RecordBatchStreamWriterOptions) {\n        super();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n\n    protected _position = 0;\n    protected _started = false;\n    protected _autoDestroy: boolean;\n    protected _writeLegacyIpcFormat: boolean;\n    // @ts-ignore\n    protected _sink = new AsyncByteQueue();\n    protected _schema: Schema | null = null;\n    protected _dictionaryBlocks: FileBlock[] = [];\n    protected _recordBatchBlocks: FileBlock[] = [];\n    protected _dictionaryDeltaOffsets = new Map<number, number>();\n\n    public toString(sync: true): string;\n    public toString(sync?: false): Promise<string>;\n    public toString(sync: any = false) {\n        return this._sink.toString(sync) as Promise<string> | string;\n    }\n    public toUint8Array(sync: true): Uint8Array;\n    public toUint8Array(sync?: false): Promise<Uint8Array>;\n    public toUint8Array(sync: any = false) {\n        return this._sink.toUint8Array(sync) as Promise<Uint8Array> | Uint8Array;\n    }\n\n    public writeAll(input: Table<T> | Iterable<RecordBatch<T>>): this;\n    public writeAll(input: AsyncIterable<RecordBatch<T>>): Promise<this>;\n    public writeAll(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<any> | Table<T> | Iterable<RecordBatch<T>> | AsyncIterable<RecordBatch<T>>) {\n        if (isPromise<any>(input)) {\n            return input.then((x) => this.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, <any> input);\n    }\n\n    public get closed() { return this._sink.closed; }\n    public [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    public toDOMStream(options?: ReadableDOMStreamOptions) { return this._sink.toDOMStream(options); }\n    public toNodeStream(options?: import('stream').ReadableOptions) { return this._sink.toNodeStream(options); }\n\n    public close() {\n        return this.reset()._sink.close();\n    }\n    public abort(reason?: any) {\n        return this.reset()._sink.abort(reason);\n    }\n    public finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    public reset(sink: WritableSink<ArrayBufferViewInput> = this._sink, schema: Schema<T> | null = null) {\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink as AsyncByteQueue;\n        } else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            } else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n\n        if (!schema || !(compareSchemas(schema, this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            } else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n\n        return this;\n    }\n\n    public write(payload?: Table<T> | RecordBatch<T> | Iterable<RecordBatch<T>> | null) {\n        let schema: Schema<T> | null = null;\n\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        } else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        } else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n\n        if (schema && !compareSchemas(schema, this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        } else if (payload instanceof Table) {\n            this.writeAll(payload.chunks);\n        } else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n\n    protected _writeMessage<T extends MessageHeader>(message: Message<T>, alignment = 8) {\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        } else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) { this._write(buffer); }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n\n    protected _write(chunk: ArrayBufferViewInput) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMessage(Message.from(schema));\n    }\n\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n\n    protected _writeMagic() {\n        return this._write(MAGIC);\n    }\n\n    protected _writePadding(nBytes: number) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeBodyBuffers(buffers: ArrayBufferView[]) {\n        let buffer: ArrayBufferView;\n        let size: number, padding: number;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? (dictionary as any).chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n\n/** @ignore */\nexport class RecordBatchStreamWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): RecordBatchStreamWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any, options?: RecordBatchStreamWriterOptions) {\n        const writer = new RecordBatchStreamWriter<T>(options);\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n\n/** @ignore */\nexport class RecordBatchFileWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchFileWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any) {\n        const writer = new RecordBatchFileWriter<T>();\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n\n    // @ts-ignore\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMagic()._writePadding(2);\n    }\n\n    protected _writeFooter(schema: Schema<T>) {\n        const buffer = Footer.encode(new Footer(\n            schema, MetadataVersion.V4,\n            this._recordBatchBlocks, this._dictionaryBlocks\n        ));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n\n/** @ignore */\nexport class RecordBatchJSONWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchJSONWriter<T>;\n    // @ts-ignore\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: any) {\n        return new RecordBatchJSONWriter<T>().writeAll(input as any);\n    }\n\n    private _recordBatches: RecordBatch[];\n    private _dictionaries: RecordBatch[];\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n\n    protected _writeMessage() { return this; }\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) { return this; }\n    protected _writeSchema(schema: Schema<T>) {\n        return this._write(`{\\n  \"schema\": ${\n            JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)\n        }`);\n    }\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    public close() {\n\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n\n        this._dictionaries = [];\n        this._recordBatches = [];\n\n        return super.close();\n    }\n}\n\n/** @ignore */\nfunction writeAll<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, input: Table<T> | Iterable<RecordBatch<T>>) {\n    let chunks = input as Iterable<RecordBatch<T>>;\n    if (input instanceof Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nasync function writeAllAsync<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, batches: AsyncIterable<RecordBatch<T>>) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }: Field): Record<string, unknown> {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary: Vector, id: number, isDelta = false) {\n    const field = new Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n\n/** @ignore */\nfunction recordBatchToJSON(records: RecordBatch) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n"]}},"error":null,"hash":"75c9fb90ca06552c4983ab10c7ab6f37","cacheData":{"env":{}}}